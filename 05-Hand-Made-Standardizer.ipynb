{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handmade Standardizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üßëüèª‚Äçüè´ In this challenge, we are going to create our *own* StandardScaler. Are you wondering why? Glad you asked!\n",
    "\n",
    "üéØ The goals of this exercise are to:\n",
    "- understand `stateless transformers` vs. `stateful transformers`\n",
    "- manipulate `FeatureUnion`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) üìö Stateless Transformer vs. Stateful Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî¢ Consider the following training set and the following test set..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X_train = pd.DataFrame({\n",
    "    'A': {0: 1, 1: 2, 2: 3},\n",
    "    'B': {0: 4, 1: 5, 2: 6},\n",
    "    'C': {0: 7, 1: 8, 2: 9}\n",
    "})\n",
    "\n",
    "print(\"This is the training dataset:\")\n",
    "display(X_train)\n",
    "\n",
    "X_test = pd.DataFrame({\n",
    "    'A': {0: 1, 1: 2, 2: 3},\n",
    "    'B': {0: 2, 1: 3, 2: 4},\n",
    "    'C': {0: 3, 1: 4, 2: 10}\n",
    "})\n",
    "\n",
    "print(\"This is the test dataset:\")\n",
    "display(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üõ† ...and the following union which:\n",
    "- scales the features\n",
    "- creates a new feature which is the average of the other (unscaled) features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import set_config; set_config(display='diagram')\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "feature_averager = FunctionTransformer(lambda df: pd.DataFrame(1/3 * (df[\"A\"] + df[\"B\"] + df[\"C\"])))\n",
    "\n",
    "pipeline = make_union(standard_scaler, feature_averager)\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's :\n",
    "- fit the pipeline to the training set \n",
    "- and transform both the training set and the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = pd.DataFrame(pipeline.transform(X_train))\n",
    "X_train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed = pd.DataFrame(pipeline.transform(X_test))\n",
    "X_test_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üë®üèª‚Äçüè´ Notice how the `StandardScaler` and the `FunctionTransformer` are fundamentally different ‚ùóÔ∏è\n",
    "\n",
    "When we fitted the pipeline and used it to transform the training set and test set:\n",
    "\n",
    "* **`FunctionTransformer (feature_averager)`**:\n",
    "    * did _not_ \"learn\" anything during the *.fit()*\n",
    "    * just performed a **stateless transformation**: $ \\large (X_1, X_2, X_3) \\rightarrow \\frac{(X_1 + X_2 + X_3)}{3}$\n",
    "\n",
    "\n",
    "* **`StandardScaler`**:\n",
    "    * \"learned\" $\\mu_{\\color{blue}{train}}$ and $\\sigma\n",
    "   _{\\color{blue}{train}}$ during the *.fit()*\n",
    "    * performed a **stateful transformation** using these learned values both in the train set and the test set:\n",
    "        * $ \\large X_{\\color{blue}{train-scaled}} =  \\frac{X_{\\color{blue}{train}} -\\mu_{\\color{blue}{train}}}{\\sigma_{\\color{blue}{train}}}$\n",
    "        * $ \\large X_{\\color{red}{test-scaled}} =  \\frac{X_{\\color{red}{test}} -\\mu_{\\color{blue}{train}}}{\\sigma_{\\color{blue}{train}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) üíª Create your own state-full transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§î What if we would like to code our own **stateful custom transformer** ? \n",
    "\n",
    "üí™ We could code our own class !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.1) üíª Custom Standardizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "‚ùì **Questions: Coding your own class** ‚ùì\n",
    "\n",
    "1. Code your own class `CustomStandardizer` \n",
    "    * It should behave exactly like the  `StandardScaler` from Scikit Learn, this means having:\n",
    "        * a `.fit()` method which computes (\"learns\") $\\mu_{\\color{blue}{train}}$ and $\\sigma\n",
    "   _{\\color{blue}{train}}$\n",
    "        * and a `.transform()` method.\n",
    "\n",
    "\n",
    "2. Fit it on `X_train` \n",
    "\n",
    "3. Transform both `X_train` and `X_test` \n",
    "\n",
    "4. Compare your `CustomStandardizer` with the `StandardScaler` from Scikit Learn to make sure you got it right !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# 1 - Code the CustomStandardizer Class #\n",
    "#########################################\n",
    "\n",
    "# TransformerMixin inheritance is used to create fit_transform() method from fit() and transform()\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "\n",
    "\n",
    "class CustomStandardizer(TransformerMixin, BaseEstimator):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        '''\n",
    "        Stores what needs to be stored as instance attributes. \n",
    "        ReturnS \"self\" to allow chaining fit and transform.\n",
    "        '''\n",
    "        pass  # YOUR CODE HERE\n",
    "    \n",
    "    def transform(self, X, y=None): \n",
    "        pass  # YOUR CODE HERE\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# 2 - Fit the CustomStandardizer Class  #\n",
    "#########################################\n",
    "\n",
    "custom_standardizer = CustomStandardizer()\n",
    "custom_standardizer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# 3 - Transform                         #\n",
    "#########################################\n",
    "\n",
    "pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ **Test your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "tmp = CustomStandardizer()\n",
    "tmp_train = np.array(tmp.fit_transform(X_train))\n",
    "tmp_test = np.array(tmp.transform(X_test))\n",
    "\n",
    "result = ChallengeResult(\n",
    "    'standardizer', \n",
    "    X_train_transformed=tmp_train,\n",
    "    X_test_transformed=tmp_test\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>üí° <i>Hints</i> (üß™ if the tests  above fail only by a small margin) </summary>\n",
    "\n",
    "* Be careful there is a slight difference between `np.std()` and `pd.std` methods! \n",
    "    \n",
    "* This [Stack Overflow post](https://stackoverflow.com/questions/44220290/sklearn-standardscaler-result-different-to-manual-result) might help üòâ\n",
    "      \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.2) üíª Inverse Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (Inverse Transform)** ‚ùì\n",
    "\n",
    "_StandardScaler_ from Scikit Learn has a [`.inverse_transform()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler.inverse_transform) method that helps you revert back to the unscaled dataset.\n",
    "\n",
    "1. Go back to your `CustomStandardizer` class and implement your own `.inverse_transform()` method.\n",
    "\n",
    "2. Try it on your scaled training set and your scaled test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try your inverse transform and run the test down below to make sure you coded it correctly\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ **Test your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(X_train_inverse_transformed, X_train)\n",
    "assert np.allclose(X_test_inverse_transformed, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.3) üíª Complete custom pipeline!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí™ We've managed to replicate Scikit-Learn's `StandardScaler`.\n",
    "\n",
    "üå∂ Let's spice it up!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question: improve the previous `CustomStandardizer` custom transformer with a shrinking factor** ‚ùì\n",
    "\n",
    "\n",
    "The `CustomStandardizer(shrink_factor = 1)` class should take one additional argument to perform a stronger scaling, in a sense that the scaling is proportional to $\\sigma_{\\color{blue}{train}}$ üëá:\n",
    "- $ \\large X_{\\color{blue}{train-scaled}} =  (\\frac{X_{\\color{blue}{train}} -\\mu_{\\color{blue}{train}}}{\\sigma_{\\color{blue}{train}}}) \\times \\frac{1}{shrink factor}$\n",
    "- $ \\large X_{\\color{red}{test-scaled}} =  (\\frac{X_{\\color{red}{test}} -\\mu_{\\color{blue}{train}}}{\\sigma_{\\color{blue}{train}}}) \\times \\frac{1}{shrink factor}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# Custom Standardizer             #\n",
    "###################################\n",
    "\n",
    "\n",
    "\n",
    "class CustomStandardizer(TransformerMixin, BaseEstimator):\n",
    "\n",
    "    def __init__(self, shrink_factor = 1):\n",
    "        pass  # YOUR CODE HERE\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        '''\n",
    "        Stores what needs to be stored as instance attributes. \n",
    "        Returns \"self\" to allow chaining fit and transform.\n",
    "        '''\n",
    "        pass  # YOUR CODE HERE\n",
    "    \n",
    "    def transform(self, X, y=None): \n",
    "        pass  # YOUR CODE HERE\n",
    "    \n",
    "    def inverse_transform(self, X, y=None):\n",
    "        pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ **Test you new `CustomStandardizer`** custom transformer with (`shrink_factor = 2`) by fitting on `X_train` and transforming both `X_train` and `X_test` and store the transformed DataFrames into `X_train_transformed` and `X_test_transformed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ **Test your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "tmp = CustomStandardizer(shrink_factor=2).fit(X_train)\n",
    "tmp_train = np.array(tmp.fit_transform(X_train))\n",
    "tmp_test = np.array(tmp.transform(X_test))\n",
    "\n",
    "result = ChallengeResult(\n",
    "    'new_standardizer', \n",
    "    X_train_transformed=tmp_train,\n",
    "    X_test_transformed=tmp_test\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following cells to ensure you got the right transformations \n",
    "# truth_train = np.array([\n",
    "#     [-0.612372, -0.612372, -0.612372],\n",
    "#     [0.000000, 0.000000, 0.000000],\n",
    "#     [0.612372, 0.612372, 0.612372]\n",
    "# ])\n",
    "# truth_test = np.array([\n",
    "#     [-0.612372, -1.837117, -3.061862],\n",
    "#     [ 0.        , -1.224745, -2.449490],\n",
    "#     [ 0.612372, -0.612372,  1.224745]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Asserts\n",
    "# np.allclose(X_train_transformed, truth_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assert - Test\n",
    "# np.allclose(X_test_transformed, truth_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question: \"tweak\" the previous `FeatureAverager` custom transformer** ‚ùì\n",
    "\n",
    "This modified `FeatureAverager()` class:\n",
    "- still computes the average of the three different features...\n",
    "- ...and now divides the result by the maximum value for each row \n",
    "    - _Note: don't try to interpret this operation, let's just be creative and practice our skills coding a custom class :)_\n",
    "\n",
    "$$(X_1, X_2, X_3) \\rightarrow \\frac{1/3 \\times (X_1 + X_2 + X_3)}{max(X_1, X_2, X_3)}$$\n",
    "\n",
    "N.B. Think carefully about whether we are dealing with a stateful or stateless transformation here (i.e. do we need to learn information about our data before we transform - like we did with our *stateful* StandardScaler - or does it function more like our *stateless* \"feature_averager\" from above?). If the former, we'll need to write something for our .fit() - if not, we don't!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# Feature Averager                #\n",
    "###################################\n",
    "\n",
    "class FeatureAverager(TransformerMixin, BaseEstimator):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        '''\n",
    "        If needed, this method will store information instance attributes.\n",
    "        Returns \"self\".\n",
    "        '''\n",
    "        pass  # YOUR CODE HERE\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ **Test you `FeatureAverager` custom transformer** by fitting on `X_train`  and transforming both `X_train` and `X_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "tmp = FeatureAverager()\n",
    "tmp_train = np.array(tmp.fit_transform(X_train))\n",
    "tmp_test = np.array(tmp.transform(X_test))\n",
    "\n",
    "result = ChallengeResult(\n",
    "    'feature_averager', \n",
    "    X_train_transformed=tmp_train,\n",
    "    X_test_transformed=tmp_test\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (Feature Union)**‚ùì\n",
    "\n",
    "1. Use both `CustomStandardizer` and `FeatureAverager` to create a `FeatureUnion` pipeline and store it in a variable named `pipeline`.\n",
    "\n",
    "2. Fit the pipeline to `X_train` and transform both `X_train` and `X_test` (`shrink_factor = 3`)\n",
    "\n",
    "3. Make sure you pass the final test of this challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# 1 - Feature Union #\n",
    "#####################\n",
    "\n",
    "pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# 2 - Fit and Transform #\n",
    "#########################\n",
    "\n",
    "pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "tmp = pipeline\n",
    "tmp_train = np.array(tmp.fit_transform(X_train))\n",
    "tmp_test = np.array(tmp.transform(X_test))\n",
    "\n",
    "\n",
    "\n",
    "result = ChallengeResult(\n",
    "    'feature_union_custom_transformers', \n",
    "    X_train_transformed=tmp_train,\n",
    "    X_test_transformed=tmp_test\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ Congratulations! You discovered how to create your own Transformer!\n",
    "\n",
    "üíæ Don't forget to¬†`git add/commit/push`¬†your notebook...\n",
    "\n",
    "üöÄ ... and move on to the next challenge!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
